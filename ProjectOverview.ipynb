{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d32b42-2344-4706-a41b-bc9e72c9afa4",
   "metadata": {},
   "source": [
    "1. PDFs in Croatian and English are read and converted to text using the pdfplumber library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f72348-f4fb-41b7-a471-080e53311ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def read_croatian_pdfs():\n",
    "    text = []\n",
    "    sum = 0\n",
    "    for i in range(1, 15):\n",
    "        n = str(i)\n",
    "\n",
    "        try:\n",
    "            with pdfplumber.open(f'Manuals/{i}_C.pdf') as pdf:\n",
    "                text = ''\n",
    "                for page_num in range(len(pdf.pages)):\n",
    "                    page = pdf.pages[page_num]\n",
    "                    text += page.extract_text()\n",
    "        except:\n",
    "            print(f\"couldn't find a {i}_C.pdf file\")\n",
    "\n",
    "        with open(f\"Manuals/txt/{i}_C.txt\", 'w', encoding='utf-8') as txt_file:\n",
    "            txt_file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55ce834-d27d-44b0-a8a1-c24517e223c1",
   "metadata": {},
   "source": [
    "2. The text is cleaned from undesirable user manual \"spam\"\r",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003c4bc9-d6dd-4140-ab59-7dbf9b30aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cluster_text_by_punctuation(input_file_path, output_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    cleaned_text = re.sub(r'[^.!?a-zčćžđšžA-ZČĆŠŽ]', ' ', text)\n",
    "    cleaned_text = re.sub(r'\\.\\.+', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\s\\s+', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\.\\s(\\.\\s)+', ' ', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\s\\.', '.', cleaned_text)\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ff2f8-fb53-478d-a4bf-4480e1e4437e",
   "metadata": {},
   "source": [
    "3. The sentences in Croatian and English are aligned using cosine similarity and sentence vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef9045-df01-44d5-9d95-19cb1270d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "def find_best_matches(sentences_cr, sentences_en, nlp2):\n",
    "    cr_matches = []\n",
    "    en_matches = []\n",
    "    translator = Translator()\n",
    "\n",
    "    min_len = min(len(sentences_cr), len(sentences_en))\n",
    "    best_match_index = []\n",
    "    cr_index = []\n",
    "    ctrl = 0\n",
    "\n",
    "    for i in range(min_len):\n",
    "        matched = 0\n",
    "        similarities = []\n",
    "        try:\n",
    "            cr = nlp2(translator.translate(sentences_cr[i], dest='en').text).vector.reshape(1, -1)\n",
    "            ctrlNum = i - ctrl\n",
    "            step = 0\n",
    "            top_range = i+ctrlNum+1\n",
    "\n",
    "            if(top_range > min_len):\n",
    "                top_range = len(sentences_en)\n",
    "\n",
    "            for j in range(ctrlNum,top_range):\n",
    "                en = nlp2(sentences_en[j]).vector.reshape(1, -1)\n",
    "                similarities.append(cosine_similarity(cr, en)[0, 0])\n",
    "                if (similarities[step]>0.95):\n",
    "                    print(f\"got match in {i} sentence\")\n",
    "                    best_match_index.append(j)\n",
    "                    cr_index.append(i)\n",
    "                    matched = 1\n",
    "                    break\n",
    "                step+= 1\n",
    "\n",
    "            if (matched == 0):\n",
    "                ctrl += 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return best_match_index, cr_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa74ea-9807-4560-a6d3-ffa876db924e",
   "metadata": {},
   "source": [
    "4. The aligned sentences are used to create a parallel corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847b065-f206-4afb-9c63-1e7b9896d7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from nltk.translate import AlignedSent, Alignment\n",
    "import pickle\n",
    "\n",
    "cr_sentences = []\n",
    "en_sentences = []\n",
    "\n",
    "for i in range(1, 8):\n",
    "    cr_file_path = f'Manuals/txt/{i}_cMatches'\n",
    "    en_file_path = f'Manuals/txt/{i}_eMatches'\n",
    "    with open(cr_file_path, 'r', encoding='utf-8') as file:\n",
    "        cr_text = file.read()\n",
    "    with open(en_file_path, 'r', encoding='utf-8') as file:\n",
    "        en_text = file.read()\n",
    "\n",
    "    croatian_out = ast.literal_eval(cr_text)\n",
    "    english_out = ast.literal_eval(en_text)\n",
    "\n",
    "    for sent in croatian_out:\n",
    "        cr_sentences.append(sent)\n",
    "    for sent in english_out:\n",
    "        en_sentences.append(sent)\n",
    "\n",
    "aligned_sentences = []\n",
    "\n",
    "for cr_sent, en_sent in zip(cr_sentences, en_sentences):\n",
    "    alignments = [(i, i) for i in range(min(len(cr_sent), len(en_sent)))]\n",
    "\n",
    "    aligned_sent = AlignedSent(en_sent, cr_sent, Alignment(alignments))\n",
    "\n",
    "    aligned_sentences.append(aligned_sent)\n",
    "\n",
    "corpus = aligned_sentences\n",
    "\n",
    "with open(\"corpus.pkl\", \"wb\") as pickle_file:\n",
    "    pickle.dump(corpus, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39bf8d9-1266-4f2d-9089-108837d6ee7b",
   "metadata": {},
   "source": [
    "<font size=\"4\"></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
